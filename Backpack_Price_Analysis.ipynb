{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0cced528",
   "metadata": {},
   "source": [
    "# Backpack Price Category Analysis\n",
    "\n",
    "This notebook demonstrates how to perform exploratory data analysis, handle missing values, perform price category binning, and prepare features for supervised classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d25fe37",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from PriceClassification import price_classification\n",
    "from ExploratoryDA import run_exploratory_da\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "import numpy as np\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6df031b7",
   "metadata": {},
   "source": [
    "# 1. Data Loading\n",
    "Load the datasets and take a first look at their structure and the distribution of the target variable and categorical features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ac15046",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load datasets\n",
    "train = pd.read_csv('Data/train.csv')\n",
    "train_extra = pd.read_csv('Data/training_extra.csv')\n",
    "test = pd.read_csv('Data/test.csv')\n",
    "\n",
    "print(f\"Train shape: {train.shape}\")\n",
    "print(f\"Training extra shape: {train_extra.shape}\")\n",
    "print(f\"Test shape: {test.shape}\")\n",
    "\n",
    "# Show first few rows for a quick glance at the data\n",
    "print(\"\\nTrain sample:\")\n",
    "display(train.head())\n",
    "# print(\"\\nTraining Extra sample:\")\n",
    "# display(train_extra.head())\n",
    "\n",
    "# Show value counts for all categorical features (before cleaning)\n",
    "def show_categorical_counts(df, name):\n",
    "    cat_cols = [col for col in df.columns if df[col].dtype == 'object']\n",
    "    print(f\"\\n{name} categorical value counts (before cleaning):\")\n",
    "    for col in cat_cols:\n",
    "        print(f\"\\n{col} value counts:\")\n",
    "        print(df[col].value_counts())\n",
    "        print(f\"Unique categories: {df[col].nunique()}\")\n",
    "\n",
    "show_categorical_counts(train, \"Train\")\n",
    "# show_categorical_counts(train_extra, \"Training Extra\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be7efbdc",
   "metadata": {},
   "source": [
    "## 2. Cleaning and Imputation\n",
    "Remove rows with more than one missing value (for train and training_extra), then fill missing values. Show how many rows are dropped and how many values are filled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "222add07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning and Imputation\n",
    "counter = 0\n",
    "def clean_and_impute(df, drop_rows_with_many_missing=True, name=\"dataset\"):\n",
    "    global counter\n",
    "    counter += 1\n",
    "    print(f\"[Call #{counter}] Processing {name}...\")\n",
    "    df_clean = df.copy()\n",
    "    n_before = df_clean.shape[0]\n",
    "    if drop_rows_with_many_missing:\n",
    "        missing_rows = df_clean.isnull().sum(axis=1)\n",
    "        n_dropped = (missing_rows > 1).sum()\n",
    "        print(f\"{name}: Dropping {n_dropped} rows with >1 missing value.\")\n",
    "        df_clean = df_clean[missing_rows <= 1]\n",
    "    else:\n",
    "        n_dropped = 0\n",
    "    n_filled = 0\n",
    "    for col in df_clean.columns:\n",
    "        n_missing = df_clean[col].isnull().sum()\n",
    "        if n_missing > 0:\n",
    "            if df_clean[col].dtype == 'object':\n",
    "                mode_val = df_clean[col].mode(dropna=True)\n",
    "                if not mode_val.empty:\n",
    "                    df_clean[col] = df_clean[col].fillna(mode_val[0])\n",
    "            else:\n",
    "                median_val = df_clean[col].median(skipna=True)\n",
    "                df_clean[col] = df_clean[col].fillna(median_val)\n",
    "            n_filled += n_missing\n",
    "    print(f\"{name}: Filled {n_filled} missing values.\")\n",
    "    print(f\"{name}: Final shape after cleaning: {df_clean.shape}\")\n",
    "    return df_clean\n",
    "\n",
    "train_clean = clean_and_impute(train, drop_rows_with_many_missing=True, name=\"Train\")\n",
    "# train_extra_clean = clean_and_impute(train_extra, drop_rows_with_many_missing=True, name=\"Training Extra\")\n",
    "\n",
    "print(\"\\nTrain (cleaned) sample:\")\n",
    "display(train_clean.head())\n",
    "# print(\"\\nTraining Extra (cleaned) sample:\")\n",
    "# display(train_extra_clean.head())\n",
    "\n",
    "categorical_columns = [col for col in train_clean.columns if train_clean[col].dtype == 'object' or train_clean[col].dtype.name == 'category']\n",
    "print(\"\\nTrain (cleaned) categorical value counts:\")\n",
    "for col in categorical_columns:\n",
    "    print(f\"\\n{col} value counts:\")\n",
    "    print(train_clean[col].value_counts())\n",
    "    print(f\"Unique categories: {train_clean[col].nunique()}\")\n",
    "\n",
    "# categorical_columns_extra = [col for col in train_extra_clean.columns if train_extra_clean[col].dtype == 'object' or train_extra_clean[col].dtype.name == 'category']\n",
    "# print(\"\\nTraining Extra (cleaned) categorical value counts:\")\n",
    "# for col in categorical_columns_extra:\n",
    "#     print(f\"\\n{col} value counts:\")\n",
    "#     print(train_extra_clean[col].value_counts())\n",
    "#     print(f\"Unique categories: {train_extra_clean[col].nunique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cae2f3bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save cleaned data for binning function\n",
    "train_clean.to_csv('Data/train_cleaned.csv', index=False)\n",
    "# train_extra_clean.to_csv('Data/training_extra_cleaned.csv', index=False)\n",
    "\n",
    "# Bin price for both training sets\n",
    "train_binned = price_classification([{'file_path': 'Data/train_cleaned.csv'}], bins=5)[0]\n",
    "# train_extra_binned = price_classification([{'file_path': 'Data/training_extra_cleaned.csv'}], bins=5)[0]\n",
    "\n",
    "# Save binned data\n",
    "train_binned.to_csv('Data/train_cleaned_with_categories.csv', index=False)\n",
    "# train_extra_binned.to_csv('Data/training_extra_cleaned_with_categories.csv', index=False)\n",
    "\n",
    "print(train_binned['Price_Category'].value_counts())\n",
    "# print(train_extra_binned['Price_Category'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e4e1e07",
   "metadata": {},
   "source": [
    "# 4. Price Binning and Distribution Plots\n",
    "Bin the price for both training sets and show the distribution of the resulting price categories. This helps visualize class balance for classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a021675a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ...existing code for binning...\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "plt.figure(figsize=(7,4))\n",
    "sns.countplot(x='Price_Category', data=train_binned, order=sorted(train_binned['Price_Category'].unique()))\n",
    "plt.title('Train: Price Category Distribution')\n",
    "plt.xlabel('Price Category')\n",
    "plt.ylabel('Count')\n",
    "plt.show()\n",
    "\n",
    "# plt.figure(figsize=(7,4))\n",
    "# sns.countplot(x='Price_Category', data=train_extra_binned, order=sorted(train_extra_binned['Price_Category'].unique()))\n",
    "# plt.title('Training Extra: Price Category Distribution')\n",
    "# plt.xlabel('Price Category')\n",
    "# plt.ylabel('Count')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acc76f4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select which training set to use:\n",
    "# Uncomment only one of the following two lines:\n",
    "X_train = train_binned.copy()  # Use main train set\n",
    "# X_train = train_extra_binned.copy()  # Use training_extra set\n",
    "\n",
    "target_col = 'Price_Category'\n",
    "categorical_cols = ['Brand', 'Material', 'Size', 'Laptop Compartment', 'Waterproof', 'Style', 'Color']\n",
    "numerical_cols = ['Compartments', 'Weight Capacity (kg)']\n",
    "\n",
    "X = X_train[categorical_cols + numerical_cols]\n",
    "y = X_train[target_col]\n",
    "\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('cat', OneHotEncoder(drop=None, sparse_output=False), categorical_cols),\n",
    "    ('num', StandardScaler(), numerical_cols)\n",
    "], remainder='drop')\n",
    "\n",
    "X_processed = preprocessor.fit_transform(X)\n",
    "cat_features = preprocessor.named_transformers_['cat'].get_feature_names_out(categorical_cols)\n",
    "num_features = numerical_cols\n",
    "feature_names = list(cat_features) + num_features\n",
    "X_processed_df = pd.DataFrame(X_processed, columns=feature_names)\n",
    "\n",
    "print('Processed feature shape:', X_processed_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b122d6e",
   "metadata": {},
   "source": [
    "# 5. Model Training, Evaluation, and Comparison\n",
    "\n",
    "We now train and evaluate multiple supervised learning models using only the cleaned and binned train.csv. We compare results using 80/20 split, 80/10/10 split, and 5-fold cross-validation. Metrics include accuracy, precision, recall, F1-score, confusion matrix, and timing. Results are summarized in tables and plots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "361a4d6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from sklearn.model_selection import train_test_split, KFold, StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Prepare features and target\n",
    "target_col = 'Price_Category'\n",
    "categorical_cols = ['Brand', 'Material', 'Size', 'Laptop Compartment', 'Waterproof', 'Style', 'Color']\n",
    "numerical_cols = ['Compartments', 'Weight Capacity (kg)']\n",
    "\n",
    "X = train_binned[categorical_cols + numerical_cols]\n",
    "y = train_binned[target_col]\n",
    "\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('cat', OneHotEncoder(drop=None, sparse_output=False), categorical_cols),\n",
    "    ('num', StandardScaler(), numerical_cols)\n",
    "], remainder='drop')\n",
    "\n",
    "X_processed = preprocessor.fit_transform(X)\n",
    "cat_features = preprocessor.named_transformers_['cat'].get_feature_names_out(categorical_cols)\n",
    "num_features = numerical_cols\n",
    "feature_names = list(cat_features) + num_features\n",
    "X_processed_df = pd.DataFrame(X_processed, columns=feature_names)\n",
    "\n",
    "models = {\n",
    "    # 'Random Forest': RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "    # 'Decision Tree': DecisionTreeClassifier(random_state=42),\n",
    "    'SVM': SVC(random_state=42),\n",
    "    # 'k-NN': KNeighborsClassifier()\n",
    "}\n",
    "\n",
    "results = []\n",
    "\n",
    "# 80/20 Split\n",
    "def evaluate_model(model, X_train, X_test, y_train, y_test, model_name, split_name):\n",
    "    start = time.time()\n",
    "    model.fit(X_train, y_train)\n",
    "    fit_time = time.time() - start\n",
    "    start = time.time()\n",
    "    y_pred = model.predict(X_test)\n",
    "    pred_time = time.time() - start\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    prec = precision_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "    rec = recall_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    results.append({\n",
    "        'Model': model_name,\n",
    "        'Split': split_name,\n",
    "        'Accuracy': acc,\n",
    "        'Precision': prec,\n",
    "        'Recall': rec,\n",
    "        'F1': f1,\n",
    "        'Fit Time (s)': fit_time,\n",
    "        'Pred Time (s)': pred_time\n",
    "    })\n",
    "    print(f\"\\n{model_name} ({split_name}) Confusion Matrix:\")\n",
    "    print(cm)\n",
    "    return y_pred, cm\n",
    "\n",
    "# 80/20 split\n",
    "X_tr, X_te, y_tr, y_te = train_test_split(X_processed_df, y, test_size=0.2, random_state=42, stratify=y)\n",
    "for name, model in models.items():\n",
    "    evaluate_model(model, X_tr, X_te, y_tr, y_te, name, '80/20')\n",
    "\n",
    "# 80/10/10 split (train/val/test)\n",
    "X_temp, X_test, y_temp, y_test = train_test_split(X_processed_df, y, test_size=0.1, random_state=42, stratify=y)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_temp, y_temp, test_size=0.1111, random_state=42, stratify=y_temp)  # 0.1111*0.9 â‰ˆ 0.1\n",
    "for name, model in models.items():\n",
    "    print(f\"\\n{name} (80/10/10 split)\")\n",
    "    evaluate_model(model, X_train, X_val, y_train, y_val, name, '80/10/10 (val)')\n",
    "    evaluate_model(model, X_train, X_test, y_train, y_test, name, '80/10/10 (test)')\n",
    "\n",
    "# 5-fold cross-validation\n",
    "kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "for name, model in models.items():\n",
    "    accs, precs, recs, f1s, fit_times, pred_times = [], [], [], [], [], []\n",
    "    for train_idx, test_idx in kf.split(X_processed_df, y):\n",
    "        X_tr, X_te = X_processed_df.iloc[train_idx], X_processed_df.iloc[test_idx]\n",
    "        y_tr, y_te = y.iloc[train_idx], y.iloc[test_idx]\n",
    "        start = time.time()\n",
    "        model.fit(X_tr, y_tr)\n",
    "        fit_time = time.time() - start\n",
    "        start = time.time()\n",
    "        y_pred = model.predict(X_te)\n",
    "        pred_time = time.time() - start\n",
    "        accs.append(accuracy_score(y_te, y_pred))\n",
    "        precs.append(precision_score(y_te, y_pred, average='weighted', zero_division=0))\n",
    "        recs.append(recall_score(y_te, y_pred, average='weighted', zero_division=0))\n",
    "        f1s.append(f1_score(y_te, y_pred, average='weighted', zero_division=0))\n",
    "        fit_times.append(fit_time)\n",
    "        pred_times.append(pred_time)\n",
    "    results.append({\n",
    "        'Model': name,\n",
    "        'Split': '5-fold CV',\n",
    "        'Accuracy': np.mean(accs),\n",
    "        'Precision': np.mean(precs),\n",
    "        'Recall': np.mean(recs),\n",
    "        'F1': np.mean(f1s),\n",
    "        'Fit Time (s)': np.mean(fit_times),\n",
    "        'Pred Time (s)': np.mean(pred_times)\n",
    "    })\n",
    "\n",
    "# Summarize results\n",
    "df_results = pd.DataFrame(results)\n",
    "display(df_results)\n",
    "\n",
    "# Plot results\n",
    "plt.figure(figsize=(10,6))\n",
    "sns.barplot(data=df_results, x='Model', y='Accuracy', hue='Split')\n",
    "plt.title('Model Accuracy by Split')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "sns.barplot(data=df_results, x='Model', y='F1', hue='Split')\n",
    "plt.title('Model F1-score by Split')\n",
    "plt.ylabel('F1-score')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
