{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cf58d97f81d5e246",
   "metadata": {},
   "source": [
    "# Backpack Price Category Analysis\n",
    "\n",
    "This notebook demonstrates how to perform exploratory data analysis, handle missing values, perform price category binning, and prepare features for supervised classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6d25fe37",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-24T17:23:58.801587Z",
     "start_time": "2025-05-24T17:23:58.797031Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler, OrdinalEncoder, TargetEncoder, LabelEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import numpy as np\n",
    "from IPython.display import display\n",
    "import time\n",
    "from scipy.stats import spearmanr, chi2_contingency, pointbiserialr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "944aef49ba7b7c08",
   "metadata": {},
   "source": [
    "# 1. Data Loading\n",
    "Load the datasets and take a first look at their structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3057b7e367b4ba53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "# Load train datasets\n",
    "train = pd.read_csv('Data/train.csv')\n",
    "train_extra = pd.read_csv('Data/training_extra.csv')\n",
    "\n",
    "print(f\"Train shape: {train.shape}\")\n",
    "print(f\"Training extra shape: {train_extra.shape}\")\n",
    "\n",
    "# Show first few rows for a quick glance at the data\n",
    "display(train.head())\n",
    "display(train_extra.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e712299255bf678",
   "metadata": {},
   "source": [
    "# 2. Price Conversion\n",
    "The original problem is a regression problem, since \"Price\" is a continous value, our goal is to turn this into a classification problem. To achieve that we first need to divid Price into 5 categories, according to the range of values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1e6a825213c4b941",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "# Divide \"Price\" into categories\n",
    "def price_classification(df, bins):\n",
    "    min_price = np.floor(df['Price'].min())\n",
    "    max_price = np.ceil(df['Price'].max())\n",
    "\n",
    "    bin_edges = np.linspace(min_price, max_price, bins + 1)\n",
    "\n",
    "    print(f\"Price Range: {min_price} to {max_price}\")\n",
    "    print(f\"Price Bin Edges: {bin_edges}\")\n",
    "\n",
    "    df['Price_Category'] = pd.cut(df['Price'], bins=bin_edges, labels=[f'Class_{i+1}' for i in range(bins)], include_lowest=True)\n",
    "    return df\n",
    "\n",
    "# Plot price distribution\n",
    "def plot_price_distribution(df):\n",
    "    plt.figure(figsize=(10, 6))\n",
    "\n",
    "    category_counts = df['Price_Category'].value_counts().sort_index()\n",
    "\n",
    "    bars = plt.bar(category_counts.index, category_counts.values,\n",
    "                    color='skyblue', edgecolor='black')\n",
    "\n",
    "    for bar in bars:\n",
    "        height = bar.get_height()\n",
    "        plt.text(bar.get_x() + bar.get_width() / 2., height,\n",
    "                    f'{int(height)}',\n",
    "                    ha='center', va='bottom')\n",
    "\n",
    "    plt.title('Price Category Distribution')\n",
    "    plt.xlabel('Price Categories')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "train = price_classification(train, bins=5)\n",
    "print(\"Price Distribution in Train Dataset:\")\n",
    "plot_price_distribution(train)\n",
    "\n",
    "train_extra = price_classification(train_extra, bins=5)\n",
    "print(\"Price Distribution in Training Extra Dataset:\")\n",
    "plot_price_distribution(train_extra)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "572b2ad45968f8d1",
   "metadata": {},
   "source": [
    "# 3. Exploratory Data Analysis\n",
    "Analyze the dataset to understand its structure, missing values, duplicates, feature distributions, and correlation between the different features and the new \"Price_Category\"."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17d0ba8d81c1674a",
   "metadata": {},
   "source": [
    "### 3.1. Basic Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a342789f1bbc261",
   "metadata": {},
   "outputs": [],
   "source": [
    "def basic_info(df):\n",
    "    print(\"BASIC DATASET INFORMATION\")\n",
    "    print(\"--------------------------\")\n",
    "\n",
    "    print(\"\\n- First 5 rows:\")\n",
    "    print(df.head())\n",
    "\n",
    "    print(\"\\n- Data types:\")\n",
    "    print(df.dtypes)\n",
    "\n",
    "\n",
    "    type_counts = df.dtypes.value_counts()\n",
    "    print(f\"\\n- Column type distribution:\")\n",
    "    for dtype, count in type_counts.items():\n",
    "        print(f\"   - {dtype}: {count} columns\")\n",
    "\n",
    "    print(\"\\n- Basic numerical statistics:\")\n",
    "    non_id_cols = [col for col in df.columns if col.lower() != 'id']\n",
    "    print(df[non_id_cols].describe())\n",
    "\n",
    "\n",
    "    plt.figure(figsize=(6, 3))\n",
    "    plt.pie(type_counts, labels=type_counts.index, autopct='%1.1f%%')\n",
    "    plt.title('Data Types Distribution', fontsize=15)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "train_basic_info = basic_info(train)\n",
    "train_extra_basic_info = basic_info(train_extra)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a0bc55cca44e52b",
   "metadata": {},
   "source": [
    "### 3.2. Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30e396a998e2e74b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Missing Values\n",
    "def missing_values(df):\n",
    "    print(\"\\nMISSING VALUES ANALYSIS\")\n",
    "    print(\"-----------------------\")\n",
    "\n",
    "    missing = df.isnull().sum()\n",
    "    missing_percent = (missing / len(df)) * 100\n",
    "    missing_data = pd.concat([missing, missing_percent], axis=1)\n",
    "    missing_data.columns = ['Count', 'Percent']\n",
    "\n",
    "    missing_values = missing_data[missing_data['Count'] > 0].sort_values('Count')\n",
    "    if not missing_values.empty:\n",
    "        print(\"\\n- Columns with missing values:\")\n",
    "        print(missing_values)\n",
    "    else:\n",
    "        print(\"\\nNo missing values found in the dataset.\")\n",
    "\n",
    "\n",
    "missing_values_train = missing_values(train)\n",
    "missing_values_train_extra = missing_values(train_extra)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e001f6f8617e6a1",
   "metadata": {},
   "source": [
    "### 3.3. Duplicate Rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4c5f32148afebf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Duplicates\n",
    "def duplicates(df):\n",
    "    print(\"DUPLICATE ROWS ANALYSIS\")\n",
    "    print(\"-----------------------\")\n",
    "\n",
    "    duplicates = df[df.duplicated(keep=False)]\n",
    "    print(\"\\nChecking for fully duplicated rows\")\n",
    "\n",
    "    if not duplicates.empty:\n",
    "        print(f\"\\nFound {len(duplicates)} duplicate rows\")\n",
    "        print(\"\\nSample of duplicate rows:\")\n",
    "        print(duplicates.head())\n",
    "    else:\n",
    "        print(\"\\nNo duplicate rows found\")\n",
    "\n",
    "\n",
    "duplicates_train = duplicates(train)\n",
    "duplicates_train_extra = duplicates(train_extra)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bce213a38f60288d",
   "metadata": {},
   "source": [
    "### 3.4. Target Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0dac5f48e43160d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Target Variable\n",
    "def target_variable(df):\n",
    "    print(\"TARGET VARIABLE ANALYSIS\")\n",
    "    print(\"------------------------\")\n",
    "\n",
    "    target_col = 'Price_Category'\n",
    "\n",
    "    if target_col not in df.columns:\n",
    "        print(f\"Error: Target column '{target_col}' not found in the dataset.\")\n",
    "        return\n",
    "\n",
    "\n",
    "    print(\"\\n- Price statistics:\")\n",
    "    print(df['Price'].describe())\n",
    "\n",
    "\n",
    "    # Boxplot\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.boxplot(y=df['Price'])\n",
    "    plt.title('Box Plot of Price', fontsize=15)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "target_variable_train = target_variable(train)\n",
    "target_variable_train_extra = target_variable(train_extra)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d46875eb5f93e466",
   "metadata": {},
   "source": [
    "### 3.5. Feature Distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3538daa1d47355c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_distribution(df):\n",
    "    print(\"FEATURE DISTRIBUTION ANALYSIS\")\n",
    "    print(\"-----------------------------\")\n",
    "\n",
    "    target_col = 'Price_Category'\n",
    "\n",
    "    numerical_cols = [\n",
    "        col for col in df.select_dtypes(include=['int64', 'float64']).columns\n",
    "        if col not in [target_col, \"id\", \"Price\"]\n",
    "    ]\n",
    "\n",
    "    if numerical_cols:\n",
    "        print(f\"\\n- Found {len(numerical_cols)} numerical features\")\n",
    "\n",
    "        rows = 1\n",
    "        cols = 2\n",
    "\n",
    "        # Histogram\n",
    "        plt.figure(figsize=(5 * cols, 4 * rows))\n",
    "        for i, col in enumerate(numerical_cols):\n",
    "            plt.subplot(rows, cols, i + 1)\n",
    "            sns.histplot(data=df, x=col, kde=True)\n",
    "            plt.title(col)\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "        # Boxplot\n",
    "        plt.figure(figsize=(5 * cols, 4 * rows))\n",
    "        for i, col in enumerate(numerical_cols):\n",
    "            plt.subplot(rows, cols, i + 1)\n",
    "            sns.boxplot(data=df, y=col)\n",
    "            plt.title(col)\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "    else:\n",
    "        print(\"\\n- No numerical features found (excluding target)\")\n",
    "\n",
    "    columns_to_analyze = [col for col in df.columns if col != target_col and col != 'id' and col != 'Price']\n",
    "    categorical_cols = [col for col in df[columns_to_analyze].select_dtypes(include=['object', 'category']).columns]\n",
    "\n",
    "    if target_col in categorical_cols:\n",
    "        categorical_cols = categorical_cols.remove(target_col)\n",
    "\n",
    "    if categorical_cols:\n",
    "        print(f\"\\n- Found {len(categorical_cols)} categorical features\")\n",
    "\n",
    "        for col in categorical_cols:\n",
    "            value_counts = df[col].value_counts()\n",
    "            unique_count = len(value_counts)\n",
    "\n",
    "            print(f\"   - {col}: {unique_count} unique values\")\n",
    "\n",
    "            plt.figure(figsize=(12, 6))\n",
    "            sns.countplot(y=col, data=df, order=value_counts.index)\n",
    "            plt.title(f'Count of {col}', fontsize=15)\n",
    "\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "\n",
    "        if len(categorical_cols) > 10:\n",
    "            print(f\"   (and {len(categorical_cols) - 10} more categorical features)\")\n",
    "\n",
    "    else:\n",
    "        print(\"\\n- No categorical features found (excluding target)\")\n",
    "\n",
    "\n",
    "feature_distribution_train = feature_distribution(train)\n",
    "feature_distribution_train_extra = feature_distribution(train_extra)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee880140436cbc32",
   "metadata": {},
   "source": [
    "### 3.6. Features Correlations to Price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d8bbb3744293427",
   "metadata": {},
   "outputs": [],
   "source": [
    "def correlation_analysis(df):\n",
    "    print(\"CORRELATION ANALYSIS\")\n",
    "    print(\"---------------------\")\n",
    "\n",
    "    target_col = 'Price_Category'\n",
    "    correlation_timeout = 120  # seconds\n",
    "    results = {}\n",
    "\n",
    "    if target_col not in df.columns:\n",
    "        print(f\"Error: Target column '{target_col}' not found in the dataset.\")\n",
    "        return results\n",
    "\n",
    "    columns_to_analyze = [col for col in df.columns if col not in [target_col, 'id', 'Price']]\n",
    "\n",
    "    numerical_cols = [col for col in df[columns_to_analyze].select_dtypes(include=['int64', 'float64']).columns]\n",
    "    categorical_cols = [col for col in df[columns_to_analyze].select_dtypes(include=['object', 'category']).columns]\n",
    "\n",
    "    biserial_cols = ['Laptop Compartment', 'Waterproof']\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    # Map the Price_Category to numbers\n",
    "    if df[target_col].dtype == 'object' or df[target_col].dtype == 'category':\n",
    "        unique_categories = df[target_col].unique()\n",
    "        mapping = {cat: i for i, cat in enumerate(unique_categories)}\n",
    "        target_numeric = df[target_col].map(mapping)\n",
    "    else:\n",
    "        target_numeric = df[target_col]\n",
    "\n",
    "    correlation_results = []\n",
    "\n",
    "    print(\"\\n\" + \"-\" * 50)\n",
    "    print(\"NUMERICAL FEATURES - SPEARMAN CORRELATION\")\n",
    "    print(\"-\" * 50)\n",
    "    print(f\"{'Feature':<20} {'Correlation':<12} {'p-value':<12} {'Significance'}\")\n",
    "    print(\"-\" * 70)\n",
    "\n",
    "    # Analyze numerical columns using Spearman\n",
    "    numerical_results = []\n",
    "    for col in numerical_cols:\n",
    "        if df[col].isna().any():\n",
    "            valid_data = df[[col, target_col]].dropna()\n",
    "            if len(valid_data) < 2:\n",
    "                continue\n",
    "            corr, p_value = spearmanr(valid_data[col], target_numeric[valid_data.index])\n",
    "        else:\n",
    "            corr, p_value = spearmanr(df[col], target_numeric)\n",
    "\n",
    "        sig_status = \"significant\" if p_value < 0.05 else \"not significant\"\n",
    "        print(f\"{col:<20} {corr:>10.4f}   {p_value:>10.4f}   {sig_status}\")\n",
    "\n",
    "        numerical_results.append({\n",
    "            'feature': col,\n",
    "            'method': 'Spearman',\n",
    "            'correlation': corr,\n",
    "            'p_value': p_value,\n",
    "            'significance': p_value < 0.05,\n",
    "            'feature_type': 'Numerical'\n",
    "        })\n",
    "        correlation_results.append(numerical_results[-1])\n",
    "\n",
    "\n",
    "    print(\"\\n\" + \"-\" * 50)\n",
    "    print(\"ORDINAL FEATURES - SPEARMAN CORRELATION\")\n",
    "    print(\"-\" * 50)\n",
    "    print(f\"{'Feature':<20} {'Correlation':<12} {'p-value':<12} {'Significance'}\")\n",
    "    print(\"-\" * 70)\n",
    "\n",
    "    # Analyze ordinal columns using Spearman\n",
    "    ordinal_results = []\n",
    "    for col in ['Size']:\n",
    "        valid_data = df[[col, target_col]].dropna()\n",
    "        nan_count = len(df) - len(valid_data)\n",
    "        if nan_count > 0:\n",
    "            print(f\"{col:<20} - Processing without {nan_count} NaN values ({nan_count / len(df) * 100:.1f}%)\")\n",
    "\n",
    "        if df[col].dtype == 'object' or df[col].dtype == 'category':\n",
    "            unique_values = valid_data[col].unique()\n",
    "            mapping = {val: i for i, val in enumerate(unique_values)}\n",
    "            col_numeric = valid_data[col].map(mapping)\n",
    "        else:\n",
    "            col_numeric = valid_data[col]\n",
    "\n",
    "        valid_target = target_numeric[valid_data.index]\n",
    "        corr, p_value = spearmanr(col_numeric, valid_target)\n",
    "\n",
    "        sig_status = \"significant\" if p_value < 0.05 else \"not significant\"\n",
    "        print(f\"{col:<20} {corr:>10.4f}   {p_value:>10.4f}   {sig_status}\")\n",
    "\n",
    "        ordinal_results.append({\n",
    "            'feature': col,\n",
    "            'method': 'Spearman',\n",
    "            'correlation': corr,\n",
    "            'p_value': p_value,\n",
    "            'significance': p_value < 0.05,\n",
    "            'feature_type': 'Ordinal'\n",
    "        })\n",
    "        correlation_results.append(ordinal_results[-1])\n",
    "\n",
    "\n",
    "    print(\"\\n\" + \"-\" * 50)\n",
    "    print(\"CATEGORICAL FEATURES - CHI-SQUARE TEST\")\n",
    "    print(\"-\" * 50)\n",
    "    print(f\"{'Feature':<20} {'Cramer\\'s V':<12} {'p-value':<12} {'Significance'}\")\n",
    "    print(\"-\" * 70)\n",
    "\n",
    "    # Analyze categorical columns using Chi-square test\n",
    "    categorical_results = []\n",
    "    for col in categorical_cols:\n",
    "        if col == 'Size':\n",
    "            continue\n",
    "\n",
    "        valid_data = df[[col, target_col]].dropna()\n",
    "        nan_count = len(df) - len(valid_data)\n",
    "        if nan_count > 0:\n",
    "            print(f\"{col:<20} - Processing without {nan_count} NaN values ({nan_count / len(df) * 100:.1f}%)\")\n",
    "\n",
    "        try:\n",
    "            # Create contingency table\n",
    "            contingency_table = pd.crosstab(valid_data[col], valid_data[target_col])\n",
    "\n",
    "            # Check if contingency table is valid for chi-square test\n",
    "            if contingency_table.shape[0] < 2 or contingency_table.shape[1] < 2:\n",
    "                print(f\"{col:<20} {'N/A':<12} {'N/A':<12} {'N/A - Not enough unique values'}\")\n",
    "                continue\n",
    "\n",
    "            # Check if expected frequencies are too small\n",
    "            chi2, p_value, dof, expected = chi2_contingency(contingency_table)\n",
    "\n",
    "            if (expected < 5).any():\n",
    "                print(f\"{col:<20} - Warning: Some expected frequencies < 5\")\n",
    "\n",
    "            # Calculate Cramer's V as a measure of association strength\n",
    "            n = contingency_table.sum().sum()\n",
    "            min_dim = min(contingency_table.shape) - 1\n",
    "            if min_dim == 0:\n",
    "                cramers_v = 0\n",
    "            else:\n",
    "                cramers_v = np.sqrt(chi2 / (n * min_dim))\n",
    "\n",
    "            sig_status = \"significant\" if p_value < 0.05 else \"not significant\"\n",
    "            print(f\"{col:<20} {cramers_v:>10.4f}   {p_value:>10.4f}   {sig_status}\")\n",
    "\n",
    "            categorical_results.append({\n",
    "                'feature': col,\n",
    "                'method': 'Chi-square',\n",
    "                'correlation': cramers_v,\n",
    "                'p_value': p_value,\n",
    "                'significance': p_value < 0.05,\n",
    "                'feature_type': 'Nominal'\n",
    "            })\n",
    "            correlation_results.append(categorical_results[-1])\n",
    "        except Exception as e:\n",
    "            print(f\"{col:<20} {'Error':<12} {'Error':<12} {'Error: ' + str(e)}\")\n",
    "\n",
    "\n",
    "    print(\"\\n\" + \"-\" * 50)\n",
    "    print(\"BINARY FEATURES - POINT-BISERIAL CORRELATION\")\n",
    "    print(\"-\" * 50)\n",
    "    print(f\"{'Feature':<20} {'Correlation':<12} {'p-value':<12} {'Significance'}\")\n",
    "    print(\"-\" * 70)\n",
    "\n",
    "    # Analyze binary columns using Point-Biserial correlation\n",
    "    binary_results = []\n",
    "    for col in biserial_cols:\n",
    "        valid_data = df[[col, target_col]].dropna()\n",
    "        nan_count = len(df) - len(valid_data)\n",
    "        if nan_count > 0:\n",
    "            print(f\"{col:<20} - Processing without {nan_count} NaN values ({nan_count / len(df) * 100:.1f}%)\")\n",
    "\n",
    "        if valid_data[col].nunique() != 2:\n",
    "            print(f\"{col:<20} {'N/A':<12} {'N/A':<12} {'N/A - Not a binary column'}\")\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            # Convert binary column to 0/1\n",
    "            binary_col = pd.factorize(valid_data[col])[0]\n",
    "            valid_target = target_numeric[valid_data.index]\n",
    "            corr, p_value = pointbiserialr(binary_col, valid_target)\n",
    "\n",
    "            sig_status = \"significant\" if p_value < 0.05 else \"not significant\"\n",
    "            print(f\"{col:<20} {corr:>10.4f}   {p_value:>10.4f}   {sig_status}\")\n",
    "\n",
    "            binary_results.append({\n",
    "                'feature': col,\n",
    "                'method': 'Point-Biserial',\n",
    "                'correlation': corr,\n",
    "                'p_value': p_value,\n",
    "                'significance': p_value < 0.05,\n",
    "                'feature_type': 'Binary'\n",
    "            })\n",
    "            correlation_results.append(binary_results[-1])\n",
    "        except Exception as e:\n",
    "            print(f\"{col:<20} {'Error':<12} {'Error':<12} {'Error: ' + str(e)}\")\n",
    "\n",
    "    if time.time() - start_time > correlation_timeout:\n",
    "        print(f\"\\nCorrelation analysis timed out after {correlation_timeout} seconds\")\n",
    "        return results\n",
    "\n",
    "    if correlation_results:\n",
    "        results_df = pd.DataFrame(correlation_results)\n",
    "        results_df['abs_corr'] = results_df['correlation'].abs()\n",
    "        results_df = results_df.sort_values('abs_corr', ascending=False)\n",
    "\n",
    "        all_correlations = results_df.copy()\n",
    "        results_df = results_df.drop('abs_corr', axis=1)\n",
    "        results['all_correlations'] = all_correlations\n",
    "\n",
    "        print(\"\\n\" + \"=\" * 50)\n",
    "        print(\"CORRELATIONS SUMMARY\")\n",
    "        print(\"=\" * 50)\n",
    "\n",
    "        results = results_df.head(10)\n",
    "        for _, row in results.iterrows():\n",
    "            sig = \"significant\" if row['significance'] else \"not significant\"\n",
    "            print(f\"{row['feature']} ({row['feature_type']}): {row['correlation']:.4f} ({row['method']}, {sig})\")\n",
    "\n",
    "\n",
    "feature_correlation_train = correlation_analysis(train)\n",
    "feature_correlation_train_extra = correlation_analysis(train_extra)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94d41cea08e3e1a6",
   "metadata": {},
   "source": [
    "# 4. Data Preprocessing\n",
    "Prepare the data for model training by encoding categorical variables and scaling numerical features."
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 4.1. Data Cleaning and Imputation\n",
    "- Drops rows with more than one missing value\n",
    "- Fills missing values based on column type(mode for categorical and median for numeric)"
   ],
   "id": "4ef0848670b5020d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "counter = 0\n",
    "def clean_and_impute(df, drop_rows_with_many_missing=True, name=\"dataset\"):\n",
    "    global counter\n",
    "    counter += 1\n",
    "    print(f\"[Call #{counter}] Processing {name}...\")\n",
    "    df_clean = df.copy()\n",
    "    n_before = df_clean.shape[0]\n",
    "    if drop_rows_with_many_missing:\n",
    "        missing_rows = df_clean.isnull().sum(axis=1)\n",
    "        n_dropped = (missing_rows > 1).sum()\n",
    "        print(f\"{name}: Dropping {n_dropped} rows with >1 missing value.\")\n",
    "        df_clean = df_clean[missing_rows <= 1]\n",
    "    else:\n",
    "        n_dropped = 0\n",
    "    n_filled = 0\n",
    "    for col in df_clean.columns:\n",
    "        n_missing = df_clean[col].isnull().sum()\n",
    "        if n_missing > 0:\n",
    "            if df_clean[col].dtype == 'object':\n",
    "                mode_val = df_clean[col].mode(dropna=True)\n",
    "                if not mode_val.empty:\n",
    "                    df_clean[col] = df_clean[col].fillna(mode_val[0])\n",
    "            else:\n",
    "                median_val = df_clean[col].median(skipna=True)\n",
    "                df_clean[col] = df_clean[col].fillna(median_val)\n",
    "            n_filled += n_missing\n",
    "    print(f\"{name}: Filled {n_filled} missing values.\")\n",
    "    print(f\"{name}: Final shape after cleaning: {df_clean.shape}\")\n",
    "    return df_clean\n",
    "\n",
    "train_clean = clean_and_impute(train, drop_rows_with_many_missing=True, name=\"Train\")\n",
    "train_extra_clean = clean_and_impute(train_extra, drop_rows_with_many_missing=True, name=\"Training Extra\")\n",
    "\n",
    "print(\"\\nTrain (cleaned) sample:\")\n",
    "display(train_clean.head())\n",
    "print(\"\\nTraining Extra (cleaned) sample:\")\n",
    "display(train_extra_clean.head())\n",
    "\n",
    "train_clean.to_csv('Data/train_cleaned.csv', index=False)\n",
    "train_extra_clean.to_csv('Data/training_extra_cleaned.csv', index=False)"
   ],
   "id": "498a674ba98a6840"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 4.2. Categorical Variables Encoding and Normalization\n",
    "- \"Color\" was encoded using Target Encoding (replaces categories with the mean of the target variable for each group)\n",
    "- \"Size\" and \"Price_Category\" were encoded using Ordinal Encoding (substitutes categories with numeric values)\n",
    "- The rest of categorical variables uses One-Hot Encoding (converting each category into a binary column)\n",
    "- Numerical variables were normalized via standardization (scaling them to have zero mean and unit variance for balanced model training)\n",
    "- \"Price\" was excluded during pre-processing, the other features were maintained since the correlation analysis made above wasn't conclusive"
   ],
   "id": "454584845aa07903"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "target_col = 'Price_Category'\n",
    "onehot_cols = ['Brand', 'Material', 'Laptop Compartment', 'Waterproof', 'Style']\n",
    "ordinal_cols = ['Size']\n",
    "target_encode_cols = ['Color']\n",
    "numerical_cols = ['Compartments', 'Weight Capacity (kg)']\n",
    "\n",
    "X_train = train_clean\n",
    "\n",
    "target_encoder = OrdinalEncoder()\n",
    "y_numeric = target_encoder.fit_transform(X_train[[target_col]]).ravel()\n",
    "\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('onehot', OneHotEncoder(drop=None, sparse_output=False), onehot_cols),\n",
    "    ('ordinal', OrdinalEncoder(categories=[['Small', 'Medium', 'Large']]), ordinal_cols),\n",
    "    ('target', TargetEncoder(), target_encode_cols),\n",
    "    ('num', StandardScaler(), numerical_cols)\n",
    "], remainder='drop')\n",
    "\n",
    "X = X_train[onehot_cols + ordinal_cols + target_encode_cols + numerical_cols]\n",
    "X_processed = preprocessor.fit_transform(X, y_numeric)\n",
    "\n",
    "# Get the actual feature names from the preprocessor\n",
    "feature_names = preprocessor.get_feature_names_out()\n",
    "X_processed_df = pd.DataFrame(X_processed, columns=feature_names)\n",
    "y = X_train[target_col]\n",
    "\n",
    "print('Train processed feature shape:', X_processed_df.shape)\n",
    "\n",
    "# Process train_extra dataset\n",
    "X_train_extra = train_extra_clean.copy()\n",
    "\n",
    "# Convert target to numeric using the same OrdinalEncoder\n",
    "y_extra_numeric = target_encoder.transform(X_train_extra[[target_col]]).ravel()\n",
    "\n",
    "preprocessor_extra = ColumnTransformer([\n",
    "    ('onehot', OneHotEncoder(drop=None, sparse_output=False), onehot_cols),\n",
    "    ('ordinal', OrdinalEncoder(categories=[['Small', 'Medium', 'Large']]), ordinal_cols),\n",
    "    ('target', TargetEncoder(), target_encode_cols),\n",
    "    ('num', StandardScaler(), numerical_cols)\n",
    "], remainder='drop')\n",
    "\n",
    "X_extra = X_train_extra[onehot_cols + ordinal_cols + target_encode_cols + numerical_cols]\n",
    "X_extra_processed = preprocessor_extra.fit_transform(X_extra, y_extra_numeric)\n",
    "\n",
    "# Get the actual feature names from the preprocessor\n",
    "feature_names_extra = preprocessor_extra.get_feature_names_out()\n",
    "X_extra_processed_df = pd.DataFrame(X_extra_processed, columns=feature_names_extra)\n",
    "y_extra = X_train_extra[target_col]\n",
    "\n",
    "print('Train extra processed feature shape:', X_extra_processed_df.shape)"
   ],
   "id": "965273afcdae7406"
  },
  {
   "cell_type": "markdown",
   "id": "5d2883cf90abc354",
   "metadata": {},
   "source": [
    "# 5. Model Training and Evaluation\n",
    "Train and evaluate models one at a time."
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Combine both the datasets\n",
    "X_combined = pd.concat([X_processed_df, X_extra_processed_df], axis=0, ignore_index=True)\n",
    "y_combined = pd.concat([y, y_extra], axis=0, ignore_index=True)\n",
    "\n",
    "print(f\"Combined dataset shape: {X_combined.shape}\")\n",
    "print(f\"Combined target distribution:\\n{y_combined.value_counts()}\")\n",
    "\n",
    "# Split the train datasets to have some validation\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "        X_combined, y_combined, test_size=0.2, random_state=42, stratify=y_combined)\n",
    "\n",
    "print(\"Using validation split strategy\")\n",
    "print(f\"Training set size: {X_train.shape[0]}\")\n",
    "print(f\"Validation set size: {X_val.shape[0]}\")"
   ],
   "id": "12c458219355fd28"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 5.1. Decision Tree",
   "id": "a2f0a4955807475"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "models = {}\n",
    "results = {}\n",
    "\n",
    "print(\"TRAINING DECISION TREE\")\n",
    "print(\"----------------------\")\n",
    "\n",
    "dt_params = {\n",
    "    'max_depth': [3, 5, 7, 10, None],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'criterion': ['gini', 'entropy']\n",
    "}\n",
    "\n",
    "dt = DecisionTreeClassifier(random_state=42)\n",
    "dt_grid = GridSearchCV(dt, dt_params, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "dt_grid.fit(X_train, y_train)\n",
    "\n",
    "models['Decision Tree'] = dt_grid.best_estimator_\n",
    "print(f\"Best DT params: {dt_grid.best_params_}\")\n",
    "print(f\"Best DT CV score: {dt_grid.best_score_:.4f}\")"
   ],
   "id": "43b8b5bf8f253a3e"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 5.2. k-Nearest Neighbors",
   "id": "bc1ff77b7a873f76"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "\"\"\"print(\"TRAINING K-NEAREST NEIGHBORS\")\n",
    "print(\"----------------------------\")\n",
    "\n",
    "knn_params = {\n",
    "    'n_neighbors': [3, 5, 7, 9, 11, 15],\n",
    "    'weights': ['uniform', 'distance'],\n",
    "    'metric': ['euclidean', 'manhattan', 'minkowski']\n",
    "}\n",
    "\n",
    "knn = KNeighborsClassifier()\n",
    "knn_grid = GridSearchCV(knn, knn_params, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "knn_grid.fit(X_train, y_train)\n",
    "\n",
    "models['KNN'] = knn_grid.best_estimator_\n",
    "print(f\"Best KNN params: {knn_grid.best_params_}\")\n",
    "print(f\"Best KNN CV score: {knn_grid.best_score_:.4f}\")\"\"\""
   ],
   "id": "3e11a45d6e556267"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 5.3. Neural Networks",
   "id": "4e1f2e12c0b0853a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "\"\"\"print(\"TRAINING NEURAL NETWORKS (MLP)\")\n",
    "print(\"------------------------------\")\n",
    "\n",
    "nn_params = {\n",
    "    'hidden_layer_sizes': [(50,), (100,), (50, 50), (100, 50), (100, 100)],\n",
    "    'activation': ['relu', 'tanh'],\n",
    "    'alpha': [0.0001, 0.001, 0.01],\n",
    "    'learning_rate': ['constant', 'adaptive']\n",
    "}\n",
    "\n",
    "nn = MLPClassifier(random_state=42, max_iter=1000)\n",
    "nn_grid = GridSearchCV(nn, nn_params, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "nn_grid.fit(X_train, y_train)\n",
    "\n",
    "models['Neural Network'] = nn_grid.best_estimator_\n",
    "print(f\"Best NN params: {nn_grid.best_params_}\")\n",
    "print(f\"Best NN CV score: {nn_grid.best_score_:.4f}\")\"\"\""
   ],
   "id": "8a510e61706ed7ea"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 5.4. Support Vector Machine",
   "id": "9cc78cf30cdaa47b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "\"\"\"print(\"TRAINING SUPPORT VECTOR MACHINES\")\n",
    "print(\"--------------------------------\")\n",
    "\n",
    "\n",
    "svm_params = {\n",
    "    'C': [0.1, 1, 10, 100],\n",
    "    'kernel': ['linear', 'rbf', 'poly'],\n",
    "    'gamma': ['scale', 'auto', 0.001, 0.01, 0.1]\n",
    "}\n",
    "\n",
    "svm = SVC(random_state=42)\n",
    "svm_grid = GridSearchCV(svm, svm_params, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "svm_grid.fit(X_train, y_train)\n",
    "\n",
    "models['SVM'] = svm_grid.best_estimator_\n",
    "print(f\"Best SVM params: {svm_grid.best_params_}\")\n",
    "print(f\"Best SVM CV score: {svm_grid.best_score_:.4f}\")\"\"\""
   ],
   "id": "f2b170e83587f5b2"
  },
  {
   "cell_type": "markdown",
   "id": "1951199b2ed0caf2",
   "metadata": {},
   "source": [
    "# 6. Comparison of Results\n",
    "Compare the performance of all models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "176d074f32b6ea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, X_train, X_val, y_train, y_val, model_name):\n",
    "    print(f\"\\nEvaluating {model_name}...\")\n",
    "\n",
    "    # Measure training time\n",
    "    start_time = time.time()\n",
    "    model.fit(X_train, y_train)\n",
    "    fit_time = time.time() - start_time\n",
    "\n",
    "    # Measure prediction time\n",
    "    start_time = time.time()\n",
    "    y_pred = model.predict(X_val)\n",
    "    pred_time = time.time() - start_time\n",
    "\n",
    "    # Calculate metrics\n",
    "    acc = accuracy_score(y_val, y_pred)\n",
    "    prec = precision_score(y_val, y_pred, average='weighted')\n",
    "    rec = recall_score(y_val, y_pred, average='weighted')\n",
    "    f1 = f1_score(y_val, y_pred, average='weighted')\n",
    "\n",
    "    return {\n",
    "        'Model': model_name,\n",
    "        'Accuracy': acc,\n",
    "        'Precision': prec,\n",
    "        'Recall': rec,\n",
    "        'F1': f1,\n",
    "        'Fit Time (s)': fit_time,\n",
    "        'Pred Time (s)': pred_time\n",
    "    }\n",
    "\n",
    "# Evaluate all models\n",
    "print(\"EVALUATING ALL MODELS ON VALIDATION SET\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "results_list = []\n",
    "for model_name, model in models.items():\n",
    "    result = evaluate_model(model, X_train, X_val, y_train, y_val, model_name)\n",
    "    results_list.append(result)\n",
    "\n",
    "    # Print individual results\n",
    "    print(f\"\\n{model_name} Results:\")\n",
    "    print(f\"  Accuracy:    {result['Accuracy']:.4f}\")\n",
    "    print(f\"  Precision:   {result['Precision']:.4f}\")\n",
    "    print(f\"  Recall:      {result['Recall']:.4f}\")\n",
    "    print(f\"  F1 Score:    {result['F1']:.4f}\")\n",
    "    print(f\"  Fit Time:    {result['Fit Time (s)']:.4f}s\")\n",
    "    print(f\"  Pred Time:   {result['Pred Time (s)']:.6f}s\")\n",
    "\n",
    "# Create comprehensive results DataFrame\n",
    "results_df = pd.DataFrame(results_list)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"COMPREHENSIVE RESULTS COMPARISON\")\n",
    "print(\"=\" * 80)\n",
    "print(results_df.round(4))\n",
    "\n",
    "# Find best performing model for each metric\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"BEST PERFORMING MODELS BY METRIC\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "metrics = ['Accuracy', 'Precision', 'Recall', 'F1']\n",
    "for metric in metrics:\n",
    "    best_idx = results_df[metric].idxmax()\n",
    "    best_model = results_df.loc[best_idx, 'Model']\n",
    "    best_score = results_df.loc[best_idx, metric]\n",
    "    print(f\"Best {metric:10}: {best_model:15} ({best_score:.4f})\")\n",
    "\n",
    "# Find fastest models\n",
    "fastest_fit_idx = results_df['Fit Time (s)'].idxmin()\n",
    "fastest_pred_idx = results_df['Pred Time (s)'].idxmin()\n",
    "\n",
    "print(f\"Fastest Fit:   {results_df.loc[fastest_fit_idx, 'Model']:15} ({results_df.loc[fastest_fit_idx, 'Fit Time (s)']:.4f}s)\")\n",
    "print(f\"Fastest Pred:  {results_df.loc[fastest_pred_idx, 'Model']:15} ({results_df.loc[fastest_pred_idx, 'Pred Time (s)']:.6f}s)\")\n",
    "\n",
    "# Create visualizations\n",
    "fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "fig.suptitle('Model Performance Comparison', fontsize=16, fontweight='bold')\n",
    "\n",
    "# Performance metrics\n",
    "metrics_to_plot = ['Accuracy', 'Precision', 'Recall', 'F1']\n",
    "for i, metric in enumerate(metrics_to_plot):\n",
    "    ax = axes[0, i] if i < 2 else axes[1, i-2]\n",
    "    bars = ax.bar(results_df['Model'], results_df[metric],\n",
    "                  color=['skyblue', 'lightcoral', 'lightgreen', 'gold'])\n",
    "    ax.set_title(f'{metric} Comparison')\n",
    "    ax.set_ylabel(metric)\n",
    "    ax.tick_params(axis='x', rotation=45)\n",
    "\n",
    "    # Add value labels on bars\n",
    "    for bar in bars:\n",
    "        height = bar.get_height()\n",
    "        ax.text(bar.get_x() + bar.get_width()/2., height + 0.005,\n",
    "                f'{height:.3f}', ha='center', va='bottom')\n",
    "\n",
    "# Training time comparison\n",
    "ax = axes[1, 2]\n",
    "bars = ax.bar(results_df['Model'], results_df['Fit Time (s)'],\n",
    "              color='orange', alpha=0.7)\n",
    "ax.set_title('Training Time Comparison')\n",
    "ax.set_ylabel('Time (seconds)')\n",
    "ax.tick_params(axis='x', rotation=45)\n",
    "\n",
    "# Add value labels on bars\n",
    "for bar in bars:\n",
    "    height = bar.get_height()\n",
    "    ax.text(bar.get_x() + bar.get_width()/2., height + height*0.02,\n",
    "            f'{height:.3f}s', ha='center', va='bottom')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Create a performance ranking\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"OVERALL PERFORMANCE RANKING\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Calculate composite score (you can adjust weights as needed)\n",
    "weights = {'Accuracy': 0.3, 'Precision': 0.25, 'Recall': 0.25, 'F1': 0.2}\n",
    "results_df['Composite_Score'] = sum(results_df[metric] * weight\n",
    "                                   for metric, weight in weights.items())\n",
    "\n",
    "# Sort by composite score\n",
    "ranking_df = results_df.sort_values('Composite_Score', ascending=False)\n",
    "print(\"Ranking based on weighted composite score:\")\n",
    "print(\"(Accuracy: 30%, Precision: 25%, Recall: 25%, F1: 20%)\")\n",
    "print()\n",
    "\n",
    "for i, (_, row) in enumerate(ranking_df.iterrows(), 1):\n",
    "    print(f\"{i}. {row['Model']:15} - Composite Score: {row['Composite_Score']:.4f}\")\n",
    "\n",
    "# Detailed comparison table for easy copying\n",
    "print(\"\\n\" + \"=\" * 100)\n",
    "print(\"DETAILED RESULTS TABLE\")\n",
    "print(\"=\" * 100)\n",
    "detailed_results = results_df[['Model', 'Accuracy', 'Precision', 'Recall', 'F1',\n",
    "                              'Fit Time (s)', 'Pred Time (s)']].round(4)\n",
    "print(detailed_results.to_string(index=False))\n",
    "\n",
    "# Performance vs Speed Analysis\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"PERFORMANCE vs SPEED ANALYSIS\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "for _, row in results_df.iterrows():\n",
    "    model_name = row['Model']\n",
    "    accuracy = row['Accuracy']\n",
    "    fit_time = row['Fit Time (s)']\n",
    "    pred_time = row['Pred Time (s)']\n",
    "\n",
    "    # Performance tier\n",
    "    if accuracy >= 0.95:\n",
    "        perf_tier = \"Excellent\"\n",
    "    elif accuracy >= 0.90:\n",
    "        perf_tier = \"Good\"\n",
    "    elif accuracy >= 0.85:\n",
    "        perf_tier = \"Fair\"\n",
    "    else:\n",
    "        perf_tier = \"Poor\"\n",
    "\n",
    "    # Speed tier (for training)\n",
    "    if fit_time <= 0.1:\n",
    "        speed_tier = \"Very Fast\"\n",
    "    elif fit_time <= 1.0:\n",
    "        speed_tier = \"Fast\"\n",
    "    elif fit_time <= 10.0:\n",
    "        speed_tier = \"Moderate\"\n",
    "    else:\n",
    "        speed_tier = \"Slow\"\n",
    "\n",
    "    print(f\"{model_name:15} - {perf_tier:9} Performance, {speed_tier:10} Training\")\n",
    "\n",
    "# Save results to CSV for further analysis\n",
    "results_df.to_csv('model_comparison_results.csv', index=False)\n",
    "print(f\"\\nResults saved to 'model_comparison_results.csv'\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
